# Arkaa Indexer

This project provides a modular and production-ready framework for ingesting and parsing PDF and DOCX documents into structured chunks using LangChain-compatible & Unstructured.io loaders. It includes logging, error handling, environment-based configuration, and abstracted loaders for flexibility.

## ğŸ”§ Features

- Support for both PDF (`PyPDFLoader`,`Unstructured`) and DOCX (`Unstructured`) formats
- Modular loader architecture with a factory pattern
- Custom logging for each loader
- configuration via `.env` & `.yaml`
- Validation and Error handling included
- Processing techniques including, normalizing document structure,language detection & translation. 
- Embedding Creations using `OpenAI` & Storing them in `PGVector`

## ğŸ“ Folder Structure
```bash
â”œâ”€â”€ main.py # Entry point for processing documents
â”œâ”€â”€ loaders/ # Contains loader classes
â”‚ â”œâ”€â”€ base_loader.py
â”‚ â”œâ”€â”€ pypdf_loader.py  # Utilizes PyPDF Loader
â”‚ â”œâ”€â”€ doc_loader.py    # Uses unstructured.io to parse word documents
  â”œâ”€â”€ unstruct_pdf_loader.py  # Uses unstrucutred.io to parse pdf documents, choose this for complex pdf documents
â”‚ â””â”€â”€ loader_factory.py # That chooses the above loaders based on the document extension
â”œâ”€â”€ data/  # contains sample data documents 
â”œâ”€â”€ processors/
â”‚   â”œâ”€â”€ language_detector.py # uses langid to detect the language
â”‚   â”œâ”€â”€ preprocessor_pipeline.py # Entire Processing pipeline
â”‚   â”œâ”€â”€ translation_process.py # performs the translation process 
â”‚   â””â”€â”€ translator/
â”‚       â”œâ”€â”€ argos_translator.py # Open-Source & Offline Translators
â”‚       â”œâ”€â”€ base_translator.py 
â”‚       â”œâ”€â”€ google_translator.py # Uses Google Translator API
â”‚       â”œâ”€â”€ microsoft_translator.py # Uses Microsoft Translator
â”‚       â”œâ”€â”€ openai_translator.py # LLM as a Translator 
â”‚       â””â”€â”€ translator_factory.py # Chooses the Translator
â”œâ”€â”€ prompts/ 
    â”œâ”€â”€ openai_translator_prompt.py # Prompt for the LLM Translator
â”œâ”€â”€ vectorstores/
â”‚   â”œâ”€â”€ base_vectorstore.py
â”‚   â”œâ”€â”€ pgvector_store.py  # Postgres Vector Database
â”‚   â””â”€â”€ vectorstore_factory.py # Choose between the vectorstores.
â”œâ”€â”€ app_utils/   
  â”œâ”€â”€ app.log   # Stores all the application Log
â”‚ â”œâ”€â”€ logger.py # Logger Config File
  â”œâ”€â”€ exceptions.py # Defines the Custom Exceptions 
â”‚ â””â”€â”€ validators.py # for validating file paths
â”‚ â””â”€â”€ yaml_loader.py # for loading & overriding the config File.
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ base_embedder.py
â”‚   â””â”€â”€ openai_embedder.py # Uses Open AI Embedding 
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml # Config File that drives the entire indexing process.
â”œâ”€â”€ api/                           # API layer
â”‚   â””â”€â”€ v1/
â”‚       â”œâ”€â”€ celery_worker.py       # Celery app and task registration
â”‚       â”œâ”€â”€ ingest_route.py        # FastAPI route for document ingestion
â”‚       â”œâ”€â”€ schemas/
â”‚       â”‚   â””â”€â”€ ingest_schema.py   # Pydantic schema for API input validation
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â””â”€â”€ ingest_service.py  # Service logic for handling ingestion [Indexing Logic]
â”‚       â””â”€â”€ tasks/
â”‚           â””â”€â”€ indexing_task.py  # Celery background indexing task, entry point for celery
â”œâ”€â”€ .env   # to store credentials
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸš€ Getting Started


### 1. Clone the repository
```bash
git clone https://github.com/spiredata/Arkaa_BackEnd.git
cd Arkaa_BackEnd
```
### 2. Create & Activate Virtual Environment
```bash
conda create -n arkaaenv python=3.10
conda activate arkaaenv
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```
### 4. Run RabbitMQ
```bash
docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:4-management
```
### 5. Run the Celery Task

The below command is only for windows OS

```bash
celery -A api.v1.celery_worker.celery_app worker --loglevel=info --concurrency=4 -Q indexing_queue -pool=solo
```
OR

```bash
pip install gevent

celery -A api.v1.celery_worker.celery_app worker --loglevel=info --concurrency=4 -Q indexing_queue -P gevent
```

For other Operating Systems, [Celery will utilize its default concurrency module "prefork"]
```bash
celery -A api.v1.celery_worker.celery_app worker --loglevel=info --concurrency=4 -Q indexing_queue
```

## Input Schema (FastAPI)
```bash
{
  "file_paths": [
    {
      "id": 0,
      "path": "string"
    }
  ],
  "collection_name": "string",
  "base_path": "string"
}
```
